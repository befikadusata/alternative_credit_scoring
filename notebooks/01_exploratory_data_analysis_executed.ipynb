{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b498bd8",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea521e",
   "metadata": {
    "papermill": {
     "duration": 0.007018,
     "end_time": "2025-12-01T21:27:12.842310",
     "exception": false,
     "start_time": "2025-12-01T21:27:12.835292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis - LendingClub Dataset\n",
    "\n",
    "## Project: Alternative Credit Scoring Platform\n",
    "\n",
    "This notebook performs initial exploratory data analysis on the LendingClub dataset to understand the features, distributions, and data quality issues. The dataset contains information about loans issued between 2007 and 2018, with a target variable indicating whether a loan defaulted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a1a3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T21:27:12.851863Z",
     "iopub.status.busy": "2025-12-01T21:27:12.851559Z",
     "iopub.status.idle": "2025-12-01T21:27:18.434956Z",
     "shell.execute_reply": "2025-12-01T21:27:18.434048Z"
    },
    "papermill": {
     "duration": 5.589495,
     "end_time": "2025-12-01T21:27:18.435890",
     "exception": false,
     "start_time": "2025-12-01T21:27:12.846395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Set up plotting styles\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72a367",
   "metadata": {
    "papermill": {
     "duration": 0.002729,
     "end_time": "2025-12-01T21:27:18.441401",
     "exception": false,
     "start_time": "2025-12-01T21:27:18.438672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Let's load the LendingClub dataset and examine its basic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e29991",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf8b75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T21:27:18.448705Z",
     "iopub.status.busy": "2025-12-01T21:27:18.448106Z",
     "iopub.status.idle": "2025-12-01T21:27:18.856540Z",
     "shell.execute_reply": "2025-12-01T21:27:18.855399Z"
    },
    "papermill": {
     "duration": 0.41373,
     "end_time": "2025-12-01T21:27:18.857659",
     "exception": true,
     "start_time": "2025-12-01T21:27:18.443929",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/LC_loans_granting_model_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/raw/LC_loans_granting_model_dataset.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display basic information about the dataset\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDataset shape:\u001b[39m\u001b[33m'\u001b[39m, df.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/credit-scoring-MqODdzRX-py3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/credit-scoring-MqODdzRX-py3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/credit-scoring-MqODdzRX-py3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/credit-scoring-MqODdzRX-py3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/credit-scoring-MqODdzRX-py3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/raw/LC_loans_granting_model_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/raw/LC_loans_granting_model_dataset.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nDataset info:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce14b62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f7833",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7311045",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Dataset Overview\n",
    "\n",
    "Based on the information from Zenodo, this dataset has been specifically prepared for granting models that make decisions on loan approval based on information available at application time. It includes loans with final status (either \"Fully Paid\" or \"Default\") to avoid data leakage.\n",
    "\n",
    "**Target Variable**: Default (binary)\n",
    "- 0 = Fully Paid\n",
    "- 1 = Default (charged off)\n",
    "\n",
    "### Features\n",
    "\n",
    "1. **Loan Identification**: `id`, `issue_d`\n",
    "2. **Quantitative Variables**: `revenue`, `dti_n`, `loan_amnt`, `fico_n`, `experience_c`\n",
    "3. **Categorical Variables**: `emp_length`, `purpose`, `home_ownership_n`, `addr_state`, `zip_code`\n",
    "4. **Textual Variables**: `title`, `desc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962fe81",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Target Variable Analysis\n",
    "\n",
    "Let's examine the distribution of the target variable to understand the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060f968",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze the target variable distribution\n",
    "target_counts = df['Default'].value_counts()\n",
    "target_percentages = df['Default'].value_counts(normalize=True) * 100\n",
    "\n",
    "print('Target variable distribution:')\n",
    "print(target_counts)\n",
    "print('\\nTarget variable percentages:')\n",
    "print(target_percentages)\n",
    "\n",
    "# Visualize the target distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(target_counts.values, labels=['Fully Paid (0)', 'Default (1)'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribution of Target Variable')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data=df, x='Default')\n",
    "plt.title('Count of Each Target Class')\n",
    "plt.xlabel('Default Status (0=Fully Paid, 1=Default)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e345ee7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Missing Values Analysis\n",
    "\n",
    "Let's check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5cf3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "}).sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "print('Features with missing values (top 10):')\n",
    "print(missing_df[missing_df['Missing Count'] > 0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74876046",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Numerical Features Analysis\n",
    "\n",
    "Let's examine the distributions of numerical features and their relationship with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf246d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols.remove('Default')  # Remove target variable from numerical columns\n",
    "\n",
    "print('Numerical features:', numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b96816",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribution plots for numerical features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "        \n",
    "    # Plot distribution by target\n",
    "    sns.histplot(data=df, x=col, hue='Default', kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col} by Default Status')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(numerical_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9b03a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features by target\n",
    "numerical_stats = df.groupby('Default')[numerical_cols].describe()\n",
    "print('Statistical summary by Default status:')\n",
    "numerical_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2d88d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Categorical Features Analysis\n",
    "\n",
    "Let's examine the categorical features and their relationship with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca7d91",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print('Categorical features:', categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1427e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "for col in categorical_cols:\n",
    "    print(f'\\nFeature: {col}')\n",
    "    print(f'Unique values: {df[col].nunique()}')\n",
    "    print('Top 10 values:')\n",
    "    print(df[col].value_counts().head(10))\n",
    "    \n",
    "    # Create a cross-tabulation with the target variable\n",
    "    crosstab = pd.crosstab(df[col], df['Default'], normalize='index') * 100\n",
    "    print('\\nPercentage of defaults by category (top 10):')\n",
    "    print(crosstab.sort_values(by=1, ascending=False).head(10))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03692500",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize categorical features vs target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(categorical_cols[:4]):  # Show top 4 categorical features\n",
    "    # Calculate default rate by category\n",
    "    default_rate = df.groupby(col)['Default'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Create bar plot\n",
    "    sns.barplot(x=default_rate.index[:10], y=default_rate.values[:10], ax=axes[i])\n",
    "    axes[i].set_title(f'Default Rate by {col} (Top 10 Categories)')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Default Rate')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccd90b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Feature Correlations\n",
    "\n",
    "Let's examine correlations between numerical features to identify potential multicollinearity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f849d3e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6f101",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data Quality Issues\n",
    "\n",
    "Let's check for potential data quality issues such as outliers, inconsistent values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52468858",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for outliers in numerical features using IQR method\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Check outliers for each numerical feature\n",
    "for col in numerical_cols:\n",
    "    outliers = detect_outliers_iqr(df, col)\n",
    "    print(f'{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}% of data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c3833",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Key Findings and Hypotheses\n",
    "\n",
    "### Initial Findings:\n",
    "1. **Dataset Size**: The dataset contains [fill in number] records with [fill in number] features\n",
    "2. **Target Distribution**: The dataset is [balanced/imbalanced] with [X]% of loans defaulting\n",
    "3. **Missing Values**: [State any significant missing value patterns]\n",
    "4. **Feature Relationships**: [Note any obvious patterns between features and target]\n",
    "\n",
    "### Hypotheses:\n",
    "1. **FICO Score**: Lower FICO scores are likely associated with higher default rates\n",
    "2. **Debt-to-Income Ratio**: Higher DTI ratios may correlate with increased default risk\n",
    "3. **Loan Amount**: The relationship between loan amount and default risk may be complex\n",
    "4. **Employment Length**: Shorter employment history might indicate higher risk\n",
    "5. **Purpose**: Loan purpose may affect default rates (e.g. debt consolidation vs. small business)\n",
    "\n",
    "### Data Quality Notes:\n",
    "- [Note any data quality issues identified]\n",
    "- [Note any potential preprocessing steps needed]\n",
    "\n",
    "### Next Steps:\n",
    "1. Perform feature engineering to create additional predictive features\n",
    "2. Address missing values and outliers\n",
    "3. Prepare data for modeling\n",
    "4. Develop baseline models for comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.193265,
   "end_time": "2025-12-01T21:27:21.711288",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/01_exploratory_data_analysis.ipynb",
   "output_path": "notebooks/01_exploratory_data_analysis_executed.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T21:27:10.518023",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}